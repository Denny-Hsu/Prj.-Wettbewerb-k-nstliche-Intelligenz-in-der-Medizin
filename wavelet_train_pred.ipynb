{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Wavelet and Gradient Boosting Classifier, compared to one with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,f1_score,recall_score,precision_score\n",
    "from ecgdetectors import Detectors\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten\n",
    "from keras.layers import Dense, Dropout, LeakyReLU\n",
    "# from keras.utils import plot_model\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE, KMeansSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Diese Datei sollte nicht verändert werden und wird von uns gestellt und zurückgesetzt.\n",
    "\n",
    "Funktionen zum Laden und Speichern der Dateien\n",
    "\n",
    "\n",
    "@author: Maurice Rohr\n",
    "\"\"\"\n",
    "import csv\n",
    "import scipy.io as sio\n",
    "import os\n",
    "\n",
    "\n",
    "### Achtung! Diese Funktion nicht verändern.\n",
    "\n",
    "def load_references(folder='../training/'):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : TYPE, optional\n",
    "        Ort der Trainingsdaten. The default is '../training/'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ecg_leads : list of numpy arrays\n",
    "        EKG Signale.\n",
    "    ecg_labels : list of str\n",
    "        gleiche Laenge wie ecg_leads. Werte: 'N','A','O','~'\n",
    "    fs : float\n",
    "        Sampling Frequenz.\n",
    "    ecg_names : list of str\n",
    "\n",
    "    '''\n",
    "    ecg_leads = list()\n",
    "    ecg_labels = list()\n",
    "    ecg_names = list()\n",
    "    fs = 300\n",
    "    with open(folder + 'REFERENCE.csv') as csv_file:  # Einlesen der Liste mit Dateinamen und Zuordnung\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            data = sio.loadmat(folder + row[0] + '.mat')  # Import der EKG-Dateien\n",
    "            ecg_lead = data['val'][0]\n",
    "            label = row[1]\n",
    "            ecg_leads.append(ecg_lead)\n",
    "            ecg_labels.append(label)\n",
    "            ecg_names.append(row[0])\n",
    "    print(str(len(ecg_leads)) + \"\\t Dateien wurden geladen.\")\n",
    "\n",
    "    return ecg_leads, ecg_labels, fs, ecg_names\n",
    "\n",
    "\n",
    "### Achtung! Diese Funktion nicht verändern.\n",
    "\n",
    "def save_predictions(predictions):\n",
    "    '''\n",
    "    Speichert Prädiktion in CSV-Datei\n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : list of tuples\n",
    "        (\"Name der Datei\", Label). Label : ['N','A','O','~']\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    if os.path.exists(\"PREDICTIONS.csv\"):\n",
    "        os.remove(\"PREDICTIONS.csv\")\n",
    "\n",
    "    with open('PREDICTIONS.csv', mode='w', newline='') as predictions_file:\n",
    "        predictions_writer = csv.writer(predictions_file, delimiter=',')\n",
    "        for prediction in predictions:\n",
    "            predictions_writer.writerow([prediction[0], prediction[1]])\n",
    "        print(str(len(predictions)) + \"\\t Labels wurden geschrieben.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## N ==0 , A == 1\n",
    "\n",
    "def F1_SCORE(y_test,y_pred):\n",
    "#     df_gt = pd.read_csv(\"../training/REFERENCE.csv\", header=None)  # Wahrheit\n",
    "#     df_pred = pd.read_csv(\"prediction.csv\", header=None)   # Klassifikationen\n",
    "\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "#         gt_name = dataset['file_name'][i]\n",
    "#         gt_class = dataset['label'][i]\n",
    "\n",
    "#         pred_indx = df_pred[df_pred[0]==gt_name].index.values\n",
    "\n",
    "#         if not pred_indx.size:\n",
    "#             print(\"Prediktion für \" + gt_name + \" fehlt, nehme \\\"normal\\\" an.\")\n",
    "#             pred_class = 1\n",
    "#         else:\n",
    "#             pred_indx = pred_indx[0]\n",
    "#             pred_class = df_pred[1][pred_indx]\n",
    "\n",
    "        gt_class = y_test[i]\n",
    "        pred_class = y_pred[i]\n",
    "        \n",
    "        if gt_class == 1 and pred_class == 1:\n",
    "            TP += 1\n",
    "        if gt_class == 0 and pred_class == 0:\n",
    "            TN +=1\n",
    "        if gt_class == 0 and pred_class == 1:\n",
    "            FP += 1\n",
    "        if gt_class == 1 and pred_class == 0:\n",
    "            FN += 1\n",
    "        \n",
    "    F1 = TP / (TP + 1/2*(FP+FN))      \n",
    "    \n",
    "#     prec = TP /(TP+FP)\n",
    "#     recall = TP / (TP+FN)\n",
    "#     F1 = 2 /( (1/prec) + (1/recall) )  \n",
    "#     F1 = 2 * prec * recall / (prec + recall)\n",
    "    print(F1,TN,FP,FN,TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\t Dateien wurden geladen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cheweihsu/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:234: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/Users/cheweihsu/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:195: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/Users/cheweihsu/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0     1     2     3     4     5     6     7     8     9  ...  18278  \\\n",
      "0        8     8     8     8     8     8     7     7     7     8  ...    0.0   \n",
      "1     -504  -602  -704  -803  -886  -926  -921  -900  -892  -887  ...    0.0   \n",
      "2       23    24    26    32    40    49    57    61    61    58  ...    0.0   \n",
      "3      -55   -69   -81   -93  -104  -115  -124  -133  -138  -137  ...    0.0   \n",
      "4      -14   -16   -18   -20   -21   -25   -38   -53   -58   -60  ...    0.0   \n",
      "5      -10   -15   -22   -28   -29   -27   -25   -21   -13    10  ...    0.0   \n",
      "6      492   589   690   794   885   915   926   925   914   907  ...    0.0   \n",
      "7     -196  -248  -302  -335  -357  -372  -381  -381  -375  -366  ...    0.0   \n",
      "8      -25   -50   -68   -84   -97  -106  -112  -116  -119  -122  ...    0.0   \n",
      "9      -36   -74  -104  -135  -167  -201  -227  -245  -260  -273  ...    0.0   \n",
      "10      41    50    62    75    90    98   105   111   116   119  ...    0.0   \n",
      "11     -59   -64   -68   -71   -74   -77   -80   -81   -81   -80  ...    0.0   \n",
      "12     -33   -46   -51   -55   -57   -59   -60   -62   -63   -64  ...    0.0   \n",
      "13     104   134   166   196   212   219   225   230   234   236  ...    0.0   \n",
      "14   -1319 -1503 -1663 -1803 -1913 -1961 -1818 -1590 -1434 -1272  ...    0.0   \n",
      "15    -104  -135  -166  -191  -201  -207  -211  -215  -217  -220  ...    0.0   \n",
      "16    -827  -985 -1147 -1305 -1435 -1499 -1499 -1469 -1450 -1430  ...    0.0   \n",
      "17     582   702   807   893   962   997   984   945   927   915  ...    0.0   \n",
      "18    -116  -147  -178  -210  -234  -242  -246  -248  -249  -250  ...    0.0   \n",
      "19     164   195   226   258   276   287   294   299   301   303  ...    0.0   \n",
      "20       2     2     3     4     6     8    10    12    13    14  ...    0.0   \n",
      "21     -26   -27   -29   -32   -35   -39   -43   -47   -51   -55  ...    0.0   \n",
      "22     -52   -62   -71   -81   -92   -99   -99   -96   -94   -92  ...    0.0   \n",
      "23     -73   -89  -104  -109  -112  -114  -116  -117  -118  -118  ...    0.0   \n",
      "24     200   250   302   338   358   369   377   382   384   385  ...    0.0   \n",
      "25     167   210   260   292   330   359   372   379   383   386  ...    0.0   \n",
      "26      84   110   138   169   204   234   246   253   258   260  ...    0.0   \n",
      "27     727   862  1001  1143  1266  1327  1327  1298  1280  1266  ...    0.0   \n",
      "28      41    41    40    37    32    12   -48  -144  -235  -313  ...    0.0   \n",
      "29     288   344   407   473   518   535   541   537   530   526  ...    0.0   \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
      "4072  -133  -157  -181  -215  -247  -265  -277  -286  -304  -301  ...    0.0   \n",
      "4073  -121  -144  -169  -185  -196  -195  -179  -167  -158  -150  ...    0.0   \n",
      "4074  -680  -818  -953 -1076 -1177 -1220 -1213 -1165 -1129 -1098  ...    0.0   \n",
      "4075  -295  -283  -264  -239  -214  -181  -130  -121  -158  -241  ...    0.0   \n",
      "4076   661   778   915  1058  1178  1236  1238  1213  1190  1174  ...    0.0   \n",
      "4077   -22   -24   -32   -58   -80   -91   -98  -103  -108  -111  ...    0.0   \n",
      "4078    73    94   108   116   121   126   132   136   134   129  ...    0.0   \n",
      "4079   169   222   275   327   381   439   511   633   790   982  ...    0.0   \n",
      "4080   515   616   723   832   924   955   964   950   933   918  ...    0.0   \n",
      "4081   -54   -50   -37     1    67   148   249   361   472   576  ...    0.0   \n",
      "4082   -68   -81   -90   -78   -40    23   115   224   328   415  ...    0.0   \n",
      "4083   657   779   903  1018  1107  1135  1122  1085  1066  1054  ...    0.0   \n",
      "4084  -555  -657  -760  -859  -941  -972  -965  -929  -896  -874  ...    0.0   \n",
      "4085   -16   -30   -47   -66   -85  -104  -115  -123  -130  -134  ...    0.0   \n",
      "4086  -120  -155  -187  -216  -229  -235  -240  -245  -248  -250  ...    0.0   \n",
      "4087    59    81    99   120   131   137   143   148   153   156  ...    0.0   \n",
      "4088  -487  -586  -681  -775  -856  -884  -893  -896  -894  -889  ...    0.0   \n",
      "4089 -1777 -2073 -2360 -2626 -2834 -2954 -2839 -2658 -2568 -2403  ...    0.0   \n",
      "4090   600   718   840   957  1051  1082  1071  1029  1003   982  ...    0.0   \n",
      "4091   204   257   314   369   416   433   442   448   453   456  ...    0.0   \n",
      "4092   623   744   870   996  1102  1156  1153  1130  1120  1113  ...    0.0   \n",
      "4093   978  1174  1381  1591  1772  1852  1881  1882  1867  1855  ...    0.0   \n",
      "4094  -430  -507  -585  -660  -705  -721  -692  -660  -635  -621  ...    0.0   \n",
      "4095    59    82    93    99   104   109   112   115   117   119  ...    0.0   \n",
      "4096   419   506   589   662   726   757   753   734   723   712  ...    0.0   \n",
      "4097     6     6     5     4     3    -1   -26   -59   -90  -121  ...    0.0   \n",
      "4098   604   723   848   969  1066  1110  1102  1073  1060  1051  ...    0.0   \n",
      "4099    16    19    33    63    81    93   101   109   113   116  ...    0.0   \n",
      "4100   160   192   215   230   237   232   216   191   157   125  ...    0.0   \n",
      "4101   155   189   220   263   311   349   360   367   374   383  ...    0.0   \n",
      "\n",
      "      18279  18280  18281  18282  18283  18284  18285        file_name  label  \n",
      "0       0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00001      N  \n",
      "1       0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00002      N  \n",
      "2       0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00004      N  \n",
      "3       0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00006      N  \n",
      "4       0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00007      N  \n",
      "5       0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00012      N  \n",
      "6       0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00013      N  \n",
      "7       0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00014      N  \n",
      "8       0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00016      A  \n",
      "9       0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00018      N  \n",
      "10      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00021      N  \n",
      "11      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00022      N  \n",
      "12      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00023      N  \n",
      "13      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00024      N  \n",
      "14      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00025      N  \n",
      "15      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00026      N  \n",
      "16      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00029      N  \n",
      "17      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00030      N  \n",
      "18      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00032      N  \n",
      "19      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00033      N  \n",
      "20      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00036      N  \n",
      "21      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00039      N  \n",
      "22      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00040      N  \n",
      "23      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00041      N  \n",
      "24      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00042      N  \n",
      "25      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00044      A  \n",
      "26      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00046      N  \n",
      "27      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00047      N  \n",
      "28      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00048      N  \n",
      "29      0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_00052      N  \n",
      "...     ...    ...    ...    ...    ...    ...    ...              ...    ...  \n",
      "4072    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05961      N  \n",
      "4073    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05962      N  \n",
      "4074    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05964      N  \n",
      "4075    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05965      N  \n",
      "4076    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05966      A  \n",
      "4077    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05968      N  \n",
      "4078    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05970      N  \n",
      "4079    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05971      N  \n",
      "4080    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05972      A  \n",
      "4081    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05973      N  \n",
      "4082    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05974      N  \n",
      "4083    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05975      N  \n",
      "4084    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05976      N  \n",
      "4085    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05978      N  \n",
      "4086    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05979      N  \n",
      "4087    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05980      N  \n",
      "4088    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05981      N  \n",
      "4089    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05982      N  \n",
      "4090    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05983      N  \n",
      "4091    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05985      N  \n",
      "4092    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05986      N  \n",
      "4093    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05988      N  \n",
      "4094    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05989      N  \n",
      "4095    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05991      A  \n",
      "4096    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05992      N  \n",
      "4097    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05993      N  \n",
      "4098    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05994      N  \n",
      "4099    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05995      N  \n",
      "4100    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_05997      A  \n",
      "4101    0.0    0.0    0.0    0.0    0.0    0.0    0.0  train_ecg_06000      N  \n",
      "\n",
      "[4102 rows x 18288 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 896, 1: 130})\n"
     ]
    }
   ],
   "source": [
    "ecg_leads,ecg_labels,fs,ecg_names = load_references() # Importiere EKG-Dateien, zugehörige Diagnose, Sampling-Frequenz (Hz) und Name                                                # Sampling-Frequenz 300 Hz\n",
    "# print('ecg_leads: ', ecg_leads)\n",
    "# print('ecg_names: ', ecg_names)\n",
    "# print('ecg_labels: ', ecg_labels)\n",
    "\n",
    "\n",
    "detectors = Detectors(fs)                                 # Initialisierung des QRS-Detektors\n",
    "sdnn_normal = np.array([])                                # Initialisierung der Feature-Arrays\n",
    "sdnn_afib = np.array([])\n",
    "sdnn_total =[]\n",
    "\n",
    "for idx, ecg_lead in enumerate(ecg_leads):\n",
    "    r_peaks = detectors.hamilton_detector(ecg_lead)     # Detektion der QRS-Komplexe\n",
    "    sdnn = np.std(np.diff(r_peaks)/fs*1000)             # Berechnung der Standardabweichung der Schlag-zu-Schlag Intervalle (SDNN) in Millisekunden\n",
    "    sdnn_total = np.append(sdnn_total, r_peaks)  # Kombination der beiden SDNN-Listen\n",
    "\n",
    "    if ecg_labels[idx]=='N':\n",
    "        sdnn_normal = np.append(sdnn_normal, sdnn)         # Zuordnung zu \"Normal\"\n",
    "    if ecg_labels[idx]=='A':\n",
    "        sdnn_afib = np.append(sdnn_afib, sdnn)             # Zuordnung zu \"Vorhofflimmern\"\n",
    "\n",
    "\n",
    "\n",
    "# print(sdnn_total.shape)\n",
    "\n",
    "# # df means data frame\n",
    "df = pd.DataFrame(ecg_leads).fillna(0) # To avoid NAN problems, fill 0 for the train matrices\n",
    "df['file_name'] = pd.Series(ecg_names) # don't need .mat from file's name\n",
    "# print('df: ',df)\n",
    "df['label'] = pd.Series(ecg_labels)\n",
    "# print('df: ',df)\n",
    "dataset = df[(df[\"label\"] == 'N') | (df[\"label\"] == 'A')].reset_index(drop=True) # only keep A and N\n",
    "print(dataset)\n",
    "\n",
    "\n",
    "# Divide dataset into train-,valid- and test-dataset\n",
    "# train,valid,test = 60%,20%,20%\n",
    "X = dataset.iloc[:, :-2].values # all rows, columns without file_name and label\n",
    "y = dataset[\"label\"].values\n",
    "# print('X:',X.shape,'\\n',X)\n",
    "# print('y:',y.shape)\n",
    "\n",
    "# X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "for n, i in enumerate(y):\n",
    "    if i == \"N\":\n",
    "        y[n] = 0\n",
    "    elif i == \"A\":\n",
    "        y[n] = 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10,stratify=y)\n",
    "# x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.25, random_state=10)\n",
    "\n",
    "import collections\n",
    "result = collections.Counter(y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ecg_features(ecg_data, ecg_labels, waveletname):\n",
    "    list_features = []\n",
    "    list_unique_labels = list(set(ecg_labels))\n",
    "    list_labels = [list_unique_labels.index(elem) for elem in ecg_labels]\n",
    "    for signal in ecg_data:\n",
    "        list_coeff = pywt.wavedec(signal, waveletname)\n",
    "        features = []\n",
    "        for coeff in list_coeff:\n",
    "            features += get_features(coeff)\n",
    "        list_features.append(features)\n",
    "    return list_features, list_labels\n",
    "\n",
    "X_train_ecg, Y_train_ecg = get_ecg_features(x_train, y_train, 'db4')\n",
    "X_test_ecg, Y_test_ecg = get_ecg_features(x_test, y_test, 'db4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "=======================================GET ECG FEATURE================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_cls: 0.4102564102564103\n",
      "cls_cm:  [[871  25]\n",
      " [ 90  40]]\n",
      "cls_cm_test:\n",
      "\n",
      "0.41025641025641024 871 25 90 40\n"
     ]
    }
   ],
   "source": [
    "cls = GradientBoostingClassifier(n_estimators=10000)\n",
    "cls.fit(X_train_ecg, Y_train_ecg)\n",
    "\n",
    "cls_pred_test = cls.predict(X_test_ecg)\n",
    "\n",
    "f1_cls_test = f1_score(list(Y_test_ecg), list(cls_pred_test))\n",
    "print('The f1_cls:', f1_cls_test)\n",
    "cls_cm_test =confusion_matrix(list(Y_test_ecg), list(cls_pred_test))\n",
    "print('cls_cm: ',cls_cm_test)\n",
    "\n",
    "print('cls_cm_test:\\n')\n",
    "F1_SCORE(y_test, cls_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "====================================OVERSAMPLING AND GER ECG FEATURE======================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "x_over, y_over = SMOTE(random_state=42).fit_resample(list(x_train), list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2685, 1: 2685})\n"
     ]
    }
   ],
   "source": [
    "num_over = collections.Counter(y_over)\n",
    "print(num_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over_ecg, Y_over_ecg = get_ecg_features(x_over, y_over, 'db4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_cls: 0.460093896713615\n",
      "cls_cm:  [[862  34]\n",
      " [ 81  49]]\n",
      "cls_cm:\n",
      "\n",
      "0.460093896713615 862 34 81 49\n"
     ]
    }
   ],
   "source": [
    "cls = GradientBoostingClassifier(n_estimators=10000)\n",
    "cls.fit(list(X_over_ecg), list(Y_over_ecg))\n",
    "\n",
    "cls_over_pred = cls.predict(X_test_ecg)\n",
    "\n",
    "\n",
    "f1_cls = f1_score(list(Y_test_ecg), list(cls_over_pred))\n",
    "print('The f1_cls:', f1_cls)\n",
    "cls_cm=confusion_matrix(list(Y_test_ecg), list(cls_over_pred))\n",
    "print('cls_cm: ',cls_cm)\n",
    "\n",
    "print('cls_cm:\\n')\n",
    "F1_SCORE(Y_test_ecg, cls_over_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "==============================================END=================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
